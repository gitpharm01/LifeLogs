model的開發工作充滿了各種變數,
我在建立了萃取FeatureMap的神經網路,並且設定了以sigmoid為基礎的Hash code轉換程式.
在比對的時候卻發現,只要使用了python的for loop來進行運算.
CPU的運算成本會大增,且多了不必要的Computational graph.
很幸運的是我很快地在Stack overflow上找到了有關map_fn的用法,
以Lambda函式的形式解決了這個問題.

但問題總是緊接而來,由於目標是產生16個由二群hint hash code的相似值所構成的Similarity Map.
並且在map中找出峰值,整體的結構複雜且難以規劃.
對此我使用了tf.reshape來將原本76*76的samplemap切換成一維的陣列.

tensorflow 環境下的運算在很多時候和原生的python環境很不相同,
為此他擁有許多特殊的loop與運算方法,種類繁多到記不完的地步.
不得不說網路上各個論壇的大量討論串和錯誤回報給了我很大的幫助,
讓我能很快速地找出問題的根源與對應辦法.
在這個網路社群發展成熟的時代做程式設計遠比十多年前方便太多了.

但不容忽視的是我的開發進度也被拖慢了,
原本我預期上周就可開始嘗試進行loos function的設定以及訓練,
但是我目前仍卡在loos function的前一步.
----------------------------------------
The task of developing a new model contains much uncertainty.
I created the neural network for extracting the feature maps and the "sigmoid" based hash code transmutter.
When I started comparing the similarity of hash codes,
I found that computations with python loop will increase unnecessary computational graphs and CPU load will surge.

Luckily I soon found the solution by utilizing tf.map_fn and Lambda functions from a post of Stack overflow.
However, the problems always keep comming.
My goal is to produce 16 similarity maps generated by comparing sample hashs with two sets of hint hashs, 
and finally get peak value of each map.
The overall structure is complicated and hard to deal with.

To solve this problem, I used tf.reshape to flatten the 76x76 tensor of smaple hash map into a 1d tensor.

The operations under tensorflow environment are often quite different from the original python. 
For this reason, tensorflow have its own unique loop and other operations.
I must say that the tremendous bug reports and disscustions about all kinds of issues on the internet forums did help me to quickly find the cause of problems and the corresponding solutions.
It's much easier to do programming nowadays with well developed internet communities.

Still, it's not neglactable that my progress was again delayed.
I once planned to complete the task of defining loss functions last week.
But now I'm still one step behind it.

-------------------------------------

モデルの開発作業は色々な意外がある。
FeatureMapを計算するNeuralNetworkを作った、
そしてSigmoid functionをもとついてHashコードに転換するプログランを作った。
だがHash codeを比較すところ、
”PYTHON固有の　For loopを使うと、CPUの計算コストが上がる、そして必要のないComputational graphが増えた”という事を気づいた。
幸いに私は間もなくStackOverflowでMap_fnとLambda functionの使い方を見つかった。そしてこの問題を解決した。

けれど問題は次々と発生した。
私の目標は二組のHint hash code によって十六個のSimilarity mapを作る、
そしてそのMapの最大値の位置を探す。
全体の構造は複雑なので管理は難しい。
それに対して私はTf.reshape　を使って76*76*32のSample mapを1維のTensorにする。

Tensorflowの環境の下で行う計算は常に原始のPythonの計算方法と違いがある。
そのためにTensorflow は特殊のLoopと他の計算Functionを持つ。
インターネットForumで大量のディスカッションとエラー報告は本当に私を助かった。
短時間で問題の原因とその対応方法を見つかることが出来る。
インターネットが成熟に発展した時代でプログラミングをすることは以前より大分便利に成りました。

しかしわたしの開発進度は遅れている。
本来なら先週でLoose functionを作る予定だが、
今私は未だその前の一歩だ。
